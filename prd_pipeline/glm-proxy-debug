#!/usr/bin/env node

const http = require('http');
const https = require('https');
const fs = require('fs');
const path = require('path');
const net = require('net');

const TARGET = 'api.z.ai';
const TARGET_PATH = '/api/anthropic';

// Clear Claude's shell snapshots so it uses fresh function definitions
const snapshotDir = path.join(process.env.HOME, '.claude/shell-snapshots');
try {
  const files = fs.readdirSync(snapshotDir);
  files.filter(f => f.startsWith('snapshot-zsh-')).forEach(f => {
    fs.unlinkSync(path.join(snapshotDir, f));
  });
} catch {}

let PORT;
let LOG_DIR;
let requestCount = 0;

// Removed findAvailablePort - we now bind the HTTP server directly

function getLogPath(reqId, type) {
  return path.join(LOG_DIR, `${String(reqId).padStart(6, '0')}_${type}`);
}

function log(msg) {
  const ts = new Date().toISOString();
  const line = `[${ts}] ${msg}\n`;
  fs.appendFileSync(path.join(LOG_DIR, 'proxy.log'), line);
  // Log file only - don't pollute console
}

function createRequestHandler() {
  return (req, res) => {
    let body = [];
    const reqId = ++requestCount;
    const endpoint = req.url.split('?')[0];

    req.on('data', chunk => body.push(chunk));
    req.on('end', () => {
      body = Buffer.concat(body);
      const bodyStr = body.toString();

      let model = 'unknown';
      try {
        const parsed = JSON.parse(bodyStr);
        model = parsed.model || 'unknown';
      } catch {}

      log(`[REQ#${reqId}] ${req.method} ${req.url} | ${model} | ${body.length}b`);

      // Log FULL request
      fs.writeFileSync(getLogPath(reqId, 'req_headers.json'), JSON.stringify(req.headers, null, 2));
      fs.writeFileSync(getLogPath(reqId, 'req_body.txt'), bodyStr);

      // Intercept event_logging
      if (endpoint === '/api/event_logging/batch') {
        res.writeHead(200, { 'Content-Type': 'application/json' });
        res.end('{"success":true}');
        log(`[RES#${reqId}] event_logging intercepted`);
        return;
      }

      // ALWAYS force non-streaming for /v1/messages (not count_tokens) so we can inspect responses
      let modifiedBody = body;
      if (endpoint.includes('/v1/messages') && !endpoint.includes('count_tokens')) {
        try {
          const parsed = JSON.parse(bodyStr);
          // Force stream:false if it's true OR if it's missing (undefined/null)
          if (parsed.stream !== false) {
            const wasStream = parsed.stream;
            parsed.stream = false;
            modifiedBody = Buffer.from(JSON.stringify(parsed));
            log(`[REQ#${reqId}] FORCED stream:false (was: ${wasStream})`);
          }
        } catch {}
      }

      // Clean request headers - remove compression, fix host and content-length
      const cleanReqHeaders = { ...req.headers };
      delete cleanReqHeaders['accept-encoding'];
      delete cleanReqHeaders['Accept-Encoding'];
      cleanReqHeaders.host = TARGET;
      cleanReqHeaders['content-length'] = modifiedBody.length;

      const options = {
        hostname: TARGET,
        port: 443,
        path: TARGET_PATH + req.url,
        method: req.method,
        headers: cleanReqHeaders,
      };

      const startTime = Date.now();
      const proxyReq = https.request(options, proxyRes => {
        // Buffer the full response so we can inspect and fix it
        let responseBody = [];

        proxyRes.on('data', chunk => responseBody.push(chunk));
        proxyRes.on('end', () => {
          const rawResponse = Buffer.concat(responseBody);
          const duration = Date.now() - startTime;

          // Log FULL raw response
          fs.writeFileSync(getLogPath(reqId, 'res_headers.json'), JSON.stringify(proxyRes.headers, null, 2));
          fs.writeFileSync(getLogPath(reqId, 'res_body_raw.txt'), rawResponse.toString());
          fs.writeFileSync(getLogPath(reqId, 'res_status.txt'), `${proxyRes.statusCode}`);

          // Validate and normalize ALL /v1/messages responses (not count_tokens)
          let finalResponse = rawResponse;
          let forceStatus = null;
          const isMessageEndpoint = endpoint.includes('/v1/messages') && !endpoint.includes('count_tokens');

          if (isMessageEndpoint) {
            try {
              const json = JSON.parse(rawResponse.toString());

              // If this is an error response from z.ai, pass it through as-is
              // The SDK knows how to handle error responses
              if (json.error) {
                log(`[RES#${reqId}] ERROR_RESPONSE: ${JSON.stringify(json.error).slice(0, 200)}`);
                // Pass through - no modification needed
              } else {
                // This should be a message response - validate it has content
                // CRITICAL: Empty/invalid content crashes Claude SDK with "No messages returned"
                const hasValidContent = (() => {
                  if (!json.content) return false;
                  if (!Array.isArray(json.content)) return false;
                  if (json.content.length === 0) return false;
                  // Check if ANY content block has actual text or tool_use
                  return json.content.some(block => {
                    if (!block) return false;
                    if (block.type === 'text' && block.text && block.text.trim().length > 0) return true;
                    if (block.type === 'tool_use' && block.id) return true;
                    if (block.type === 'thinking') return true; // Allow thinking blocks
                    return false;
                  });
                })();

                if (!hasValidContent) {
                  // TRANSFORM to 429 so SDK retries
                  log(`[RES#${reqId}] INVALID_CONTENT (status was ${proxyRes.statusCode}) - transforming to 429`);
                  log(`[RES#${reqId}] Raw content was: ${JSON.stringify(json.content)}`);
                  log(`[RES#${reqId}] Full response: ${rawResponse.toString().slice(0, 500)}`);
                  fs.writeFileSync(getLogPath(reqId, 'invalid_content_transformed.txt'), rawResponse.toString());
                  forceStatus = 429;
                  finalResponse = Buffer.from(JSON.stringify({
                    type: 'error',
                    error: {
                      type: 'rate_limit_error',
                      message: 'Invalid/empty content from upstream - retry'
                    }
                  }));
                } else {
                  // Valid content - normalize the response structure
                  let modified = false;
                  const fixes = [];

                  // Add missing required fields
                  if (!json.id) { json.id = 'msg_' + Date.now() + Math.random().toString(36).slice(2,8); fixes.push('+id'); modified = true; }
                  if (!json.type || json.type !== 'message') { json.type = 'message'; fixes.push('+type'); modified = true; }
                  if (!json.role) { json.role = 'assistant'; fixes.push('+role'); modified = true; }
                  if (!json.model) { json.model = 'claude-sonnet-4-20250514'; fixes.push('+model'); modified = true; }
                  if (!json.stop_reason) { json.stop_reason = 'end_turn'; fixes.push('+stop_reason'); modified = true; }
                  if (json.stop_sequence === undefined) { json.stop_sequence = null; fixes.push('+stop_sequence'); modified = true; }
                  if (!json.usage) { json.usage = { input_tokens: 1, output_tokens: 1 }; fixes.push('+usage'); modified = true; }

                  // Strip non-standard z.ai fields from usage that might confuse Claude SDK
                  if (json.usage) {
                    if (json.usage.cache_read_input_tokens !== undefined) { delete json.usage.cache_read_input_tokens; fixes.push('-cache_read'); modified = true; }
                    if (json.usage.cache_creation_input_tokens !== undefined) { delete json.usage.cache_creation_input_tokens; fixes.push('-cache_create'); modified = true; }
                    if (json.usage.server_tool_use !== undefined) { delete json.usage.server_tool_use; fixes.push('-server_tool'); modified = true; }
                    if (json.usage.service_tier !== undefined) { delete json.usage.service_tier; fixes.push('-service_tier'); modified = true; }
                  }

                  if (modified) {
                    log(`[RES#${reqId}] NORMALIZED: ${fixes.join(',')}`);
                    finalResponse = Buffer.from(JSON.stringify(json));
                    fs.writeFileSync(getLogPath(reqId, 'res_body_normalized.txt'), finalResponse.toString());
                  }
                }
              }
            } catch (e) {
              // JSON parse failed - this is a malformed response, transform to 429
              log(`[RES#${reqId}] PARSE_FAIL (status ${proxyRes.statusCode}): ${e.message}`);
              log(`[RES#${reqId}] Raw body: ${rawResponse.toString().slice(0, 500)}`);
              fs.writeFileSync(getLogPath(reqId, 'parse_fail.txt'), rawResponse.toString());
              forceStatus = 429;
              finalResponse = Buffer.from(JSON.stringify({
                type: 'error',
                error: {
                  type: 'rate_limit_error',
                  message: 'Malformed response from upstream - retry'
                }
              }));
            }
          }

          const actualStatus = forceStatus || proxyRes.statusCode;
          log(`[RES#${reqId}] ${actualStatus}${forceStatus ? ' (was 200->429 INVALID_CONTENT)' : ''} (${duration}ms) ${finalResponse.length}b`);

          // Sanitize headers and forward
          const cleanHeaders = { ...proxyRes.headers };
          delete cleanHeaders['transfer-encoding'];
          delete cleanHeaders['content-encoding'];
          cleanHeaders['content-length'] = finalResponse.length;
          cleanHeaders['content-type'] = 'application/json';

          res.writeHead(forceStatus || proxyRes.statusCode, cleanHeaders);
          res.end(finalResponse);
        });
      });

      proxyReq.on('error', err => {
        const duration = Date.now() - startTime;
        log(`[ERR#${reqId}] ${err.message} (${duration}ms)`);
        fs.writeFileSync(getLogPath(reqId, 'error.txt'), `${err.message}\n${err.stack}`);
        if (!res.headersSent) {
          // CRITICAL: Return proper JSON error so SDK can parse and retry
          // Using 429 (rate_limit_error) triggers SDK's built-in retry logic
          const errorResponse = JSON.stringify({
            type: 'error',
            error: {
              type: 'rate_limit_error',
              message: `Upstream connection error: ${err.message} - retry`
            }
          });
          log(`[ERR#${reqId}] Returning 429 JSON error for SDK retry`);
          res.writeHead(429, {
            'content-type': 'application/json',
            'content-length': errorResponse.length
          });
          res.end(errorResponse);
        }
      });

      proxyReq.setTimeout(600000, () => {
        log(`[ERR#${reqId}] TIMEOUT 10min`);
        fs.writeFileSync(getLogPath(reqId, 'error.txt'), 'TIMEOUT 10min');
        proxyReq.destroy();
      });

      proxyReq.write(modifiedBody);
      proxyReq.end();
    });
  };
}

// Try to start server on a port, recursively try next port if in use
function startServer(port) {
  const server = http.createServer(createRequestHandler());

  server.once('error', (err) => {
    if (err.code === 'EADDRINUSE') {
      // Port in use, try next one immediately
      startServer(port + 1);
    } else {
      console.error(`Server error: ${err.message}`);
      process.exit(1);
    }
  });

  server.listen(port, '127.0.0.1', () => {
    PORT = port;
    LOG_DIR = `/tmp/glm-proxy-debug-${PORT}`;

    // Create log directory AFTER we have the port
    if (!fs.existsSync(LOG_DIR)) {
      fs.mkdirSync(LOG_DIR, { recursive: true });
    }

    // Print port to stdout AFTER successfully binding - no race condition!
    console.log(`PORT:${PORT}`);

    // Startup banner to console AND log file
    const banner = [
      `CWD: ${process.cwd()}`,
      '############################################################',
      'GLM DEBUG PROXY - FULL LOGGING',
      `Port: ${PORT}`,
      `Target: https://${TARGET}${TARGET_PATH}`,
      `Logs: ${LOG_DIR}/`,
      '############################################################'
    ];
    banner.forEach(line => {
      const ts = new Date().toISOString();
      const formatted = `[${ts}] ${line}`;
      console.log(formatted);
      fs.appendFileSync(path.join(LOG_DIR, 'proxy.log'), formatted + '\n');
    });
  });
}

// Start on port 9400
startServer(9400);
